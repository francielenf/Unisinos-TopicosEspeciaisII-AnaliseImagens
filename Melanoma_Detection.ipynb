{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Melanoma_Detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabcastro/Unisinos-TopicosEspeciaisII-AnaliseImagens/blob/master/Melanoma_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY1ce_ZRzH-o",
        "colab_type": "text"
      },
      "source": [
        "# Melanoma Detection\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Melanoma.jpg/300px-Melanoma.jpg)\n",
        "\n",
        "Melanoma is a type of skin cancer. It is the common type of skin cancer. On surfing the internet, we will come images of Melanoma which have a dark-black spot on the skin. We'll create a Siamese Convolutional Neural Network with TensorFlow using this notebook to detect two classes : **Melanoma and Non-Melanoma**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMsw8k3p0F5l",
        "colab_type": "text"
      },
      "source": [
        "## 1) Importing the packages\n",
        "We import the TensorFlow package along with NumPy and Keras. Also, we set the verbosity of TensorFlow to `tf.logging.ERROR` so that only errors are being printed in the output.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlo35vcvKqEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.logging.set_verbosity( tf.logging.ERROR )\n",
        "\n",
        "print( tf.VERSION )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuTDoJy-01zV",
        "colab_type": "text"
      },
      "source": [
        "## 2) Downloading the preprocessed data\n",
        "Processing and loading of data on a notebook could be time-consuming, so we directly download the processed data from GitHub.  The data was collected and processed in these steps :\n",
        "\n",
        "Images ->\n",
        "\n",
        "1. Images of Melanoma were collected from the internet ( using [Fatkun Chrome Extension](https://chrome.google.com/webstore/detail/fatkun-batch-download-ima/nnjjahlikiabnchcpehcpkdeckfgnohf) ). Some images of healthy skin were also collected.\n",
        "2. Due to the lesser amount of data, the images were augmented to increase their number upto 5041. Also, they were resized to dimensions 32 * 32 pixels.\n",
        "3. The RGB values were normalized ( brought down to the range ( 0 , 1 ) ).\n",
        "4. Converted to NumPy array of shape ( 5041 ,  32 , 32 , 3 ) \n",
        "\n",
        "Labels ->\n",
        "\n",
        "1. Pairs of images were generated. \n",
        "2. If both the images in that pair belonged to the same class then the label of 1 was assigned else 0 was assigned.\n",
        "3. Converted to NumPy array of shape ( 5041 , 1 ) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd8nXVRIKvXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import requests, zipfile, io\n",
        "\n",
        "r = requests.get( 'https://github.com/shubham0204/Dataset_Archives/blob/master/mel_detect_processed.zip?raw=true' ) \n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWWVQnKn-Yuw",
        "colab_type": "text"
      },
      "source": [
        "## 3) Reshaping the data\n",
        "\n",
        "We have total 5041 images and 5041 labels. We make a split of 4500-541 for training and validation repectively.\n",
        "\n",
        "* We squeeze the last 3 dimensions of the image array. Hence the shape transforms into ( 5041 , 32 , 32 , 3 ) -> ( 5041 , 3072 )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb-LtlscLefH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "DIMEN = 32\n",
        "\n",
        "X1 = np.load( 'processed_data/x1.npy')\n",
        "X2 = np.load( 'processed_data/x2.npy')\n",
        "Y = np.load( 'processed_data/y.npy')\n",
        "\n",
        "X1 = X1.reshape( ( X1.shape[0]  , DIMEN**2 * 3  ) ).astype( np.float32 )\n",
        "X2 = X2.reshape( ( X2.shape[0]  , DIMEN**2 * 3  ) ).astype( np.float32 )\n",
        "\n",
        "train_X1 = X1[ : 4500 ] \n",
        "train_X2 = X2[ : 4500 ] \n",
        "train_Y = Y[ : 4500 ] \n",
        "\n",
        "test_X1 = X1[ 4500 : ]\n",
        "test_X2 = X2[ 4500 : ] \n",
        "test_Y = Y[ 4500 : ]\n",
        " \n",
        "print(  train_X1.shape )\n",
        "print(  train_X2.shape )\n",
        "print(  train_Y.shape )\n",
        "\n",
        "print(test_X1.shape )\n",
        "print(test_X1.shape )\n",
        "print(test_Y.shape) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RamzZuk-_dwA",
        "colab_type": "text"
      },
      "source": [
        "## 4) Defining the Model\n",
        "\n",
        "We use Keras to build our Siamese Convolutional Neural Network. The layers will perform operations in this manner :\n",
        "\n",
        "1. Reshape the input ( from ( None , 3072 ) to ( None , 32 , 32 , 3 ) )\n",
        "2. Extract features using `Conv2D` and `MaxPooling2D` layers\n",
        "3. A `Dense` layer to produce a binary output using `sigmoid` activation function.\n",
        "4. Triplet Loss Function\n",
        "5. Produce a similarity score using `sigmoid`.\n",
        "\n",
        "Since our output is binary in nature we use `tf.keras.losses.binary_crossentropy` loss function with `tf.keras.optimizers.Adam` with a learning rate of 0.0001.\n",
        "\n",
        "You can read more about these networks from [here](https://medium.com/predict/face-recognition-from-scratch-using-siamese-networks-and-tensorflow-df03e32f8cd0).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaKnY6juLobf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "input_shape = ( (DIMEN**2) * 3 , )\n",
        "convolution_shape = ( DIMEN , DIMEN , 3 )\n",
        "\n",
        "kernel_size_1 = ( 8 , 8 )\n",
        "kernel_size_2 = ( 6 , 6 )\n",
        "kernel_size_3 = ( 4 , 4 )\n",
        "\n",
        "pool_size_1 = ( 6 , 6 )\n",
        "pool_size_2 = ( 4 , 4 )\n",
        "\n",
        "strides = 1\n",
        "\n",
        "seq_conv_model = [\n",
        "\n",
        "\ttf.keras.layers.Reshape( input_shape=input_shape , target_shape=convolution_shape),\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D( 32, kernel_size=kernel_size_1 , strides=strides ,activation='relu' ),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=pool_size_1, strides=strides ),\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D( 64, kernel_size=kernel_size_2 , strides=strides ,activation='relu'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=pool_size_2 , strides=strides),\n",
        "    \n",
        "    tf.keras.layers.Conv2D( 128, kernel_size=kernel_size_3 , strides=strides ,activation='relu'),\n",
        "    \n",
        "\ttf.keras.layers.Flatten(),\n",
        "\t\n",
        "\ttf.keras.layers.Dense( 3076 , activation=tf.keras.activations.sigmoid )\n",
        "\n",
        "]\n",
        "\n",
        "seq_model = tf.keras.Sequential( seq_conv_model )\n",
        "\n",
        "input_x1 = tf.keras.layers.Input( shape=input_shape )\n",
        "input_x2 = tf.keras.layers.Input( shape=input_shape )\n",
        "\n",
        "output_x1 = seq_model( input_x1 )\n",
        "output_x2 = seq_model( input_x2 )\n",
        "\n",
        "distance_euclid = tf.keras.layers.Lambda( lambda tensors : K.abs( tensors[0] - tensors[1] ))( [output_x1 , output_x2] )\n",
        "outputs = tf.keras.layers.Dense( 1 , activation=tf.keras.activations.sigmoid) ( distance_euclid )\n",
        "model = tf.keras.models.Model( [ input_x1 , input_x2 ] , outputs )\n",
        "\n",
        "model.compile( loss=tf.keras.losses.binary_crossentropy , optimizer=tf.keras.optimizers.Adam(lr=0.0001) , metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSNkqng7BcO_",
        "colab_type": "text"
      },
      "source": [
        "## 5) Training the model\n",
        "We train the model for 25 epochs with a batch size of 100 samples.\n",
        "\n",
        "**Inputs > `train_X1` and `train_X2`**\n",
        "\n",
        "**Outputs > `train_Y`**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rEeKeOXNBDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.fit( [ train_X1 , train_X2 ] , train_Y , epochs=25 , batch_size=100 ) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XHOHQWiCMXP",
        "colab_type": "text"
      },
      "source": [
        "## 6) Evaluate the Model\n",
        "\n",
        "We evaluate the model for its loss and accuracy on `test_X1` and `test_X2` arrays.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KINck89AcNVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics = model.evaluate( [ test_X1 , test_X2 ] , test_Y ) \n",
        "print( 'Loss of {} and Accuracy is {} %'.format( metrics[0] , metrics[1] * 100 ) ) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-p61KjxCmdG",
        "colab_type": "text"
      },
      "source": [
        "## 7) Converting to TensorFlow Lite model\n",
        "\n",
        "Since, we are going to use this model on Android, we need to convert it to a .tflite file ( [TensorFlow Lite](https://ww.tensorflow.org/lite) model ). This model will be loaded in Android and used for inferencing.\n",
        "\n",
        "**Tip: Perform [Post Training Quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) to reduce the models's size.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdcJwC7BAeM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.save( 'model.h5' ) \n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file( 'model.h5' ) \n",
        "converter.post_training_quantize = True\n",
        "tflite_model = converter.convert()\n",
        "size = open( 'recog_model.tflite' , 'wb' ).write( tflite_model ) \n",
        "print( 'Model size > {} Megabytes'.format( size / 1024**2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}